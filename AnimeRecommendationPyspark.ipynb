{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryalkoshish/big_data/blob/main/AnimeRecommendationPyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwX-QpEsd5jD",
        "outputId": "b9b642e7-334b-420d-a6fe-553cc7a6f09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required pyspark library\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col, sum\n",
        "# sparkml libraries\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS"
      ],
      "metadata": {
        "id": "wBXiMbWba_Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create spark session\n",
        "spark = SparkSession.builder.appName('Anime_Recommender').getOrCreate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Qym11fuTa6fG",
        "outputId": "c02ce08f-43c4-4a4b-8af9-78624eef8f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79a00b15a4d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1b161409e203:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Recommender</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can create our schema if we  need a specific data type enforcement to our field during loading our dataset.\n",
        "schema = StructType([\\\n",
        "    StructField(\"userid\", IntegerType(), True),\\\n",
        "    StructField(\"username\", StringType(), True),\\\n",
        "    StructField(\"movieid\", IntegerType(), True),\\\n",
        "    StructField(\"rating\", IntegerType(), True)\n",
        "    ])"
      ],
      "metadata": {
        "id": "w_t8yHH7e9TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from local\n",
        "input_path = 'users-score-2023.csv'\n",
        "# from gcp bucket\n",
        "input_path = 'gs://dataproc-staging-us-central1-441320292389-riaohl70/pyspark_retailstore_analysis/data/users-score-2023.csv'"
      ],
      "metadata": {
        "id": "JP-AP-264mJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CSV file can be downloaded from the link mentioned above.\n",
        "data = spark.read.csv(input_path,\n",
        "                      inferSchema=True,header=True) # , schema=schema #if schema needed\n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RoNcG7McXAv",
        "outputId": "98090475-ff21-431b-a1c7-8105e3f4f1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+--------------------+------+\n",
            "|user_id|Username|anime_id|         Anime Title|rating|\n",
            "+-------+--------+--------+--------------------+------+\n",
            "|      1|   Xinil|      21|           One Piece|     9|\n",
            "|      1|   Xinil|      48|         .hack//Sign|     7|\n",
            "|      1|   Xinil|     320|              A Kite|     5|\n",
            "|      1|   Xinil|      49|    Aa! Megami-sama!|     8|\n",
            "|      1|   Xinil|     304|Aa! Megami-sama! ...|     8|\n",
            "+-------+--------+--------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the number of rows in our dataset which is about 22 million records.\n",
        "data.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cHlcMBo01M3",
        "outputId": "10db2166-4ea1-4caf-e47b-a2cb229f03ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22322428"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data types for each columns\n",
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHfxCpzdlQFx",
        "outputId": "c252a075-2674-46ba-d804-2d51171fdaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user_id', 'int'),\n",
              " ('Username', 'string'),\n",
              " ('anime_id', 'int'),\n",
              " ('Anime Title', 'string'),\n",
              " ('rating', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the rating column type from string to integer\n",
        "data = data.withColumn(\"rating\",data['rating'].cast('integer'))\n",
        "# confirming the changes\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "3eWIXtqulRvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e98b9c-531c-436c-e06d-ea18e0136e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user_id', 'int'),\n",
              " ('Username', 'string'),\n",
              " ('anime_id', 'int'),\n",
              " ('Anime Title', 'string'),\n",
              " ('rating', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the null values. we use col to get the prefered column from dataframe using pyspark.sql.function and\n",
        "# sum the null values received from isNull fro that specific column through list of data columns.\n",
        "null_values = data.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in data.columns])\n"
      ],
      "metadata": {
        "id": "8mZnrYBBn9wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the null values, which are in columns anime_id, anime_title and rating being the highest about 2866 null items.\n",
        "null_values.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbec459DoZP0",
        "outputId": "ddf553c2-05f4-49c1-bba6-ba3e38a25a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+-----------+------+\n",
            "|user_id|Username|anime_id|Anime Title|rating|\n",
            "+-------+--------+--------+-----------+------+\n",
            "|      0|       0|       1|          1|  2866|\n",
            "+-------+--------+--------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since we have 259 null values in ratings. We fill them with 0 for now because when fitting the data\n",
        "# into the model it can not handle null values\n",
        "data = data.fillna(0)"
      ],
      "metadata": {
        "id": "TnDKjKJHo_9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rechecking null values\n",
        "null_counts = data.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in data.columns])\n",
        "#its okay we have 1 null values in anime title column because we will not be uing anime title feature to build our model\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_yMkPvhpRYf",
        "outputId": "f740df17-51d2-4f3f-aab7-ea840114c44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+-----------+------+\n",
            "|user_id|Username|anime_id|Anime Title|rating|\n",
            "+-------+--------+--------+-----------+------+\n",
            "|      0|       0|       0|          1|     0|\n",
            "+-------+--------+--------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical summary of our data\n",
        "data.describe().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBCvoKs5g-6V",
        "outputId": "f91ac209-a223-4eda-fecd-033406613f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+----------+-----------------+------------------+------------------+\n",
            "|summary|          user_id|  Username|         anime_id|       Anime Title|            rating|\n",
            "+-------+-----------------+----------+-----------------+------------------+------------------+\n",
            "|  count|         22322428|  22322428|         22322428|          22322427|          22322428|\n",
            "|   mean|370442.4563417564|       NaN|9530.012213053167|18677.971851610804|7.6184140452821705|\n",
            "| stddev|295264.9040922144|       NaN|11993.32492562087|109357.40231008055|1.6625702600454617|\n",
            "|    min|                1|   -------|                0|      !NVADE SHOW!|                 0|\n",
            "|    max|          1141579|zzzyeknom0|            56085|                 ◯|                10|\n",
            "+-------+-----------------+----------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting our data into train and test randomly where\n",
        "# 80% are stored in train_data for training purpose and 20% in test_data for testing.\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "_vvvmATehbDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALS (Alternating Least Squares) is a matrix factorization algorithm commonly used for collaborative filtering in recommendation systems.\n",
        "# using ALS form pyspark.ml\n",
        "# we can later optimize this parameter using hyper parameter optimization\n",
        "als = ALS(maxIter=10,\n",
        "          regParam=0.01,\n",
        "          userCol=\"user_id\",\n",
        "          itemCol=\"anime_id\",\n",
        "          ratingCol=\"rating\")\n",
        "\n",
        "# our model is ready, now lets fit it to our train data\n",
        "model = als.fit(train_data)"
      ],
      "metadata": {
        "id": "mkqs90pJhdqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using test_data we evaluate our predictions made from our model\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# checking the prediction from our model\n",
        "predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8jmfcF4hhUC",
        "outputId": "657a4deb-7db5-4e49-aca9-df426d2c0daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+--------------------+------+----------+\n",
            "|user_id|Username|anime_id|         Anime Title|rating|prediction|\n",
            "+-------+--------+--------+--------------------+------+----------+\n",
            "|      1|   Xinil|     193|            Maburaho|     7| 6.1814594|\n",
            "|      1|   Xinil|     210|             Ranma ½|     7| 7.5945907|\n",
            "|      1|   Xinil|     192|Love Hina Haru Sp...|     7| 6.8603435|\n",
            "|      1|   Xinil|      22| Tennis no Ouji-sama|     7|  7.145653|\n",
            "|      1|   Xinil|     122|Full Moon wo Saga...|     9| 7.6245384|\n",
            "|      1|   Xinil|     157|Mahou Sensei Negima!|     6|  6.445051|\n",
            "|      1|   Xinil|     190|     Love Hina Again|     8|  6.962368|\n",
            "|      1|   Xinil|      43|    Koukaku Kidoutai|     8|  8.101777|\n",
            "|      1|   Xinil|     165|           RahXephon|     8| 7.6812234|\n",
            "|      1|   Xinil|     127|        Gate Keepers|     5|  6.716782|\n",
            "|      1|   Xinil|      17|Hungry Heart: Wil...|     7| 7.1544356|\n",
            "|      1|   Xinil|     194|        Macross Zero|     8|  7.734792|\n",
            "|      1|   Xinil|      97|          Last Exile|     8| 7.9930453|\n",
            "|      1|   Xinil|      63|               DearS|     7| 6.1515493|\n",
            "|      1|   Xinil|     167|   Scrapped Princess|     8|  7.573301|\n",
            "|      1|   Xinil|     145|Kareshi Kanojo no...|     5| 7.8250523|\n",
            "|      1|   Xinil|     170|           Slam Dunk|     7|  8.252758|\n",
            "|      1|   Xinil|      71|   Full Metal Panic!|     9|  7.900668|\n",
            "|      1|   Xinil|     201|       Video Girl Ai|     7| 7.1498246|\n",
            "|      1|   Xinil|      30|Neon Genesis Evan...|    10|  8.152829|\n",
            "+-------+--------+--------+--------------------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping na values from predictions\n",
        "predictions = predictions.na.drop()\n"
      ],
      "metadata": {
        "id": "Kx8PGZSBszdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets calculate RMSE using regressionEvaluator from pyspark.ml.evaluation\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
        "rmse_value = evaluator.evaluate(predictions)\n",
        "\n",
        "# a lower RMSE value indicates better predictive accuracy,\n",
        "# as it means that the predicted values are closer to the actual values.\n",
        "# the closer to 0 means no error from the model\n",
        "print(\"Root Mean Sqaure Error \\n\" + str(rmse_value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LjmRLgFhh42",
        "outputId": "298eecca-e008-4490-ebff-3acc996614e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Sqaure Error \n",
            "1.2562565775325762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for a specific user with id 500 and retrieving two columns\n",
        "user = test_data.filter(test_data['user_id']==5615).select(['anime_id','user_id'])\n",
        "\n",
        "user.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQEcHvDjhl2b",
        "outputId": "0a17d761-1dd6-4ffb-d9f8-f6536575e523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+\n",
            "|anime_id|user_id|\n",
            "+--------+-------+\n",
            "|      16|   5615|\n",
            "|      19|   5615|\n",
            "|      43|   5615|\n",
            "|      47|   5615|\n",
            "|     177|   5615|\n",
            "|     225|   5615|\n",
            "|     232|   5615|\n",
            "|     317|   5615|\n",
            "|     543|   5615|\n",
            "|     572|   5615|\n",
            "|     813|   5615|\n",
            "|     861|   5615|\n",
            "|    1735|   5615|\n",
            "|    2001|   5615|\n",
            "|    2236|   5615|\n",
            "|    2476|   5615|\n",
            "|    2904|   5615|\n",
            "|    3091|   5615|\n",
            "|    9253|   5615|\n",
            "|    9756|   5615|\n",
            "+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# lets use  the model and to evauluate and train with the user id 5615\n",
        "recommended_anime = model.transform(user)\n",
        "\n",
        "# finally show the predection in descending order as highest score anime to be recommended.\n",
        "recommended_anime.orderBy('prediction',ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSFUc1Fjfrrq",
        "outputId": "8d939d7e-560e-4d9b-ef28-579c6991c6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----------+\n",
            "|anime_id|user_id|prediction|\n",
            "+--------+-------+----------+\n",
            "|      43|   5615|  9.105129|\n",
            "|    2236|   5615|  8.892427|\n",
            "|    9253|   5615|  8.773878|\n",
            "|    3091|   5615|  8.688642|\n",
            "|      47|   5615|  8.681513|\n",
            "|    2904|   5615|  8.665394|\n",
            "|      19|   5615|  8.630951|\n",
            "|     572|   5615|  8.500926|\n",
            "|    2001|   5615|  8.487847|\n",
            "|     861|   5615|  8.335785|\n",
            "|      16|   5615|  8.305287|\n",
            "|   11061|   5615|  8.263053|\n",
            "|    9756|   5615|  8.239414|\n",
            "|     317|   5615|  8.006407|\n",
            "|   12431|   5615|  7.889063|\n",
            "|     813|   5615| 7.8830805|\n",
            "|     543|   5615| 7.8369055|\n",
            "|   22297|   5615| 7.7805305|\n",
            "|   23283|   5615|   7.71803|\n",
            "|     232|   5615|  7.366153|\n",
            "+--------+-------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# end the spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "qUXoVuesfyyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}